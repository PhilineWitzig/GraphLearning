{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training for dataset dd\n",
      "The Accuracies per run were: [0.54237288 0.5        0.68644068 0.59322034 0.61864407 0.6440678\n",
      " 0.59322034 0.55932203 0.53846154 0.60683761 0.65254237 0.61016949\n",
      " 0.65254237 0.57627119 0.61864407 0.65254237 0.56779661 0.66949153\n",
      " 0.58119658 0.55555556 0.52542373 0.58474576 0.56779661 0.61016949\n",
      " 0.54237288 0.58474576 0.58474576 0.66101695 0.67521368 0.60683761\n",
      " 0.61864407 0.5        0.60169492 0.60169492 0.56779661 0.63559322\n",
      " 0.62711864 0.61864407 0.64102564 0.68376068 0.61864407 0.55084746\n",
      " 0.55932203 0.63559322 0.65254237 0.63559322 0.58474576 0.61016949\n",
      " 0.54700855 0.64102564 0.59322034 0.55084746 0.61016949 0.56779661\n",
      " 0.66949153 0.61864407 0.61016949 0.60169492 0.55555556 0.61538462\n",
      " 0.66101695 0.53389831 0.55932203 0.60169492 0.54237288 0.53389831\n",
      " 0.60169492 0.58474576 0.56410256 0.61538462 0.69491525 0.63559322\n",
      " 0.53389831 0.56779661 0.55084746 0.56779661 0.55932203 0.55084746\n",
      " 0.64957265 0.60683761 0.66101695 0.57627119 0.50847458 0.57627119\n",
      " 0.61016949 0.52542373 0.6440678  0.56779661 0.5982906  0.58119658\n",
      " 0.59322034 0.66949153 0.66949153 0.60169492 0.62711864 0.62711864\n",
      " 0.58474576 0.50847458 0.56410256 0.67521368] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.5977205562798783 \n",
      "\n",
      "With a standard deviation of  0.04557743692521439\n",
      "and highest achieved Accuracy of  0.6949152542372882 .\n",
      "Currently training for dataset enzymes\n",
      "The Accuracies per run were: [0.23333333 0.1        0.21666667 0.15       0.13333333 0.11666667\n",
      " 0.15       0.33333333 0.16666667 0.23333333 0.21666667 0.18333333\n",
      " 0.21666667 0.18333333 0.18333333 0.21666667 0.31666667 0.18333333\n",
      " 0.2        0.25       0.21666667 0.11666667 0.15       0.13333333\n",
      " 0.13333333 0.11666667 0.11666667 0.1        0.15       0.1\n",
      " 0.11666667 0.18333333 0.23333333 0.13333333 0.16666667 0.16666667\n",
      " 0.18333333 0.18333333 0.21666667 0.11666667 0.16666667 0.16666667\n",
      " 0.25       0.26666667 0.15       0.18333333 0.21666667 0.1\n",
      " 0.15       0.16666667 0.25       0.23333333 0.23333333 0.18333333\n",
      " 0.08333333 0.23333333 0.2        0.2        0.2        0.2\n",
      " 0.11666667 0.1        0.18333333 0.1        0.2        0.1\n",
      " 0.15       0.21666667 0.16666667 0.21666667 0.16666667 0.13333333\n",
      " 0.18333333 0.11666667 0.16666667 0.16666667 0.13333333 0.23333333\n",
      " 0.2        0.16666667 0.13333333 0.16666667 0.15       0.25\n",
      " 0.15       0.18333333 0.16666667 0.16666667 0.2        0.13333333\n",
      " 0.23333333 0.15       0.16666667 0.18333333 0.13333333 0.18333333\n",
      " 0.18333333 0.13333333 0.25       0.13333333] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.1751666666666667 \n",
      "\n",
      "With a standard deviation of  0.0481603225349111\n",
      "and highest achieved Accuracy of  0.3333333333333333 .\n",
      "Currently training for dataset nci1\n",
      "The Accuracies per run were: [0.57664234 0.58150852 0.57907543 0.59610706 0.62530414 0.60340633\n",
      " 0.41119221 0.60827251 0.49635036 0.54744526 0.57420925 0.48418491\n",
      " 0.51824818 0.60583942 0.45498783 0.59367397 0.49635036 0.48418491\n",
      " 0.486618   0.5863747  0.59854015 0.42092457 0.52068127 0.6107056\n",
      " 0.48905109 0.57420925 0.42335766 0.5620438  0.45012165 0.57420925\n",
      " 0.57664234 0.59124088 0.60827251 0.59367397 0.54744526 0.45498783\n",
      " 0.42822384 0.60097324 0.57664234 0.4136253  0.46472019 0.62773723\n",
      " 0.46715328 0.46958637 0.52798054 0.60097324 0.57420925 0.53041363\n",
      " 0.61557178 0.51581509 0.46715328 0.44282238 0.52554745 0.53527981\n",
      " 0.46715328 0.40632603 0.50608273 0.57420925 0.48175182 0.4622871\n",
      " 0.56690998 0.59124088 0.65450122 0.47688564 0.5863747  0.42092457\n",
      " 0.65206813 0.54744526 0.50364964 0.513382   0.55961071 0.4379562\n",
      " 0.59610706 0.50121655 0.57907543 0.44282238 0.60827251 0.59610706\n",
      " 0.55961071 0.49635036 0.56690998 0.57420925 0.57177616 0.47445255\n",
      " 0.60827251 0.56690998 0.55961071 0.40875912 0.48175182 0.57420925\n",
      " 0.59124088 0.45985401 0.60583942 0.49635036 0.52554745 0.55474453\n",
      " 0.49391727 0.48175182 0.59124088 0.59367397] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.5345985401459853 \n",
      "\n",
      "With a standard deviation of  0.06366711814473926\n",
      "and highest achieved Accuracy of  0.6545012165450121 .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from data_utils import get_adjacency_matrix\n",
    "from numpy import linalg as LA\n",
    "from progress.bar import Bar\n",
    "from data_utils import get_graph_label\n",
    "from dataset_parser import Parser\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "CLOSED_WALK_VECTOR_SIZE = 3 #maximal length of closed walks\n",
    "COMPUTE_KERNEL_MATRICES = False #Set true to compute all kernel matrixes from scratch, if false, the program will load previous results instead\n",
    "SVM_MAX_ITERATIONS = 10 #Number of Iterations for SVM classification\n",
    "MAX_IT = 10000 #Number of SVM iterations\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"\n",
    "    Utility function returning the datasets as list of lists with respective names and true labels for each graph\n",
    "    \"\"\"\n",
    "    names = ['dd', 'enzymes', 'nci1']\n",
    "    #logging.info(\"[INFO] Loading datasets: {}, {}, {}.\"\n",
    "                # .format(names[0], names[1], names[2]))\n",
    "\n",
    "    dd = Parser('datasets/DD')\n",
    "    enzymes = Parser('datasets/ENZYMES')\n",
    "    nci1 = Parser('datasets/NCI1')\n",
    "\n",
    "    # convert datasets into lists graphs, labels\n",
    "    datasets = [dd.parse_all_graphs(),\n",
    "                enzymes.parse_all_graphs(),\n",
    "                nci1.parse_all_graphs()]\n",
    "\n",
    "    \n",
    "    label_sets = [[get_graph_label(graph) for graph in graphs] for graphs in datasets]\n",
    "\n",
    "    return names, datasets, label_sets\n",
    "\n",
    "def compute_closed_walks_matrix(datasets, names):\n",
    "    \"\"\"\n",
    "    Computes the closed walk kernel matrix for all datasets, will save all computed results in the process in the Folder \"data\"\n",
    "    \n",
    "    :param datasets: List of datasets, where each dataset is a list of NetworkX graphs\n",
    "    :param names: List of Strings, which are the names of the dataset at the respective index\n",
    "    \n",
    "    :return: Closed Walk Matrices for each dataset as a List of Matrices\n",
    "    \"\"\"\n",
    "    #Make directory accordingly\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), \"data/closed_walk\")):\n",
    "        os.makedirs(os.path.join(os.getcwd(), \"data\", \"closed_walk\"))\n",
    "\n",
    "    # Initialize Datastructures\n",
    "    closed_walk_sets = [] #holds the respective closed walk vector for each graph for all datasets\n",
    "    matrix_set = [] \n",
    "\n",
    "    #compute all closed walk vectors for each dataset respectively\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        closed_walks = np.zeros([len(dataset), CLOSED_WALK_VECTOR_SIZE],dtype=np.int32)\n",
    "        bar = Bar(\"Processing \" + names[i], max=len(dataset))\n",
    "        for j, graph in enumerate(dataset):\n",
    "            bar.next()\n",
    "            closed_walks[j] = closed_walks_vector(graph, CLOSED_WALK_VECTOR_SIZE)\n",
    "        bar.finish()\n",
    "        \n",
    "        #Compute the Kernel matrix once all graphs of a single dataset are processed\n",
    "        kernel_matrix = np.dot(closed_walks,closed_walks.T)\n",
    "        \n",
    "        #Save the kernel:matrix and the computed vectors seperatly\n",
    "        np.save(os.path.join(os.getcwd(),\n",
    "                            \"data\", \"closed_walk\", \"dataset_\" + names[i] + \".npy\"), closed_walks)\n",
    "        np.save(os.path.join(os.getcwd(),\n",
    "                            \"data\", \"closed_walk\", \"dataset_\" + names[i] + \"_matrix\"+\".npy\"), kernel_matrix)\n",
    "\n",
    "        closed_walk_sets.append(closed_walks)\n",
    "        matrix_set.append(kernel_matrix)\n",
    "        \n",
    "    #print(closed_walk_sets)\n",
    "    return matrix_set\n",
    "\n",
    "\n",
    "def load_closed_walks(names):\n",
    "    \"\"\"\n",
    "    Utility Function loading and returning saved npy files for closed walk vectors. Will return all vectors of the dataset\n",
    "    \n",
    "    :param name: List of Names of datasets (\"dd\", \"enzymes\",\"nci1\")\n",
    "    :return: List of the respective lists of vectors\n",
    "    \n",
    "    \"\"\"\n",
    "    closed_walk_sets = []\n",
    "    for name in names:\n",
    "        closed_walks = np.load(os.path.join(os.getcwd(),\n",
    "                                            \"data\", \"closed_walk\", \"dataset_\" + name + \".npy\"))\n",
    "        closed_walk_sets.append(closed_walks)\n",
    "    #print(closed_walk_sets)    \n",
    "    return closed_walk_sets\n",
    "\n",
    "\n",
    "\n",
    "def load_kernel_matrix(name):\n",
    "    \"\"\"\n",
    "    Utility Function to return the specific closed walk kernel matrix for the given dataset\n",
    "    \n",
    "    :param name: Name of the dataset (\"dd\", \"enzymes\",\"nci1\")\n",
    "    :return: Kernel Matrix \n",
    "    \"\"\"\n",
    "    kernel_matrix = np.load(os.path.join(os.getcwd(),\n",
    "                                    \"data\", \"closed_walk\", \"dataset_\" + name+\"_matrix\" + \".npy\"))\n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def closed_walks_vector(x, max_i):\n",
    "    \"\"\"\n",
    "    Function calculating the vector of dimension max_i containing the number of closed walks of length 2 upto max_i\n",
    "    We make use of the spectral theorem for the calculation of the closed path number by using the eigenvalues\n",
    "    of the adjecency matrix\n",
    "    \n",
    "    :param x: A NetworkX Graph \n",
    "    \n",
    "    :return: Vector of dimension max_i, index i contains the number of closed walks of length i+2\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ##Initialization of used datastructures##\n",
    "    walks_x = np.zeros(max_i, dtype = np.int32)  # Vector holding the number of closed walks\n",
    "    eig_values, _ = LA.eig(get_adjacency_matrix(x))  # Vector holding the eigenvalues of the Adjecency Matrix\n",
    "\n",
    "    for i in range(max_i):\n",
    "        # Summation of the powered eigenvalues, we start with i+2\n",
    "        # since closed walks start with length 2. walks_x[0] will thus hold the walks of length 2, not 0.\n",
    "        walks_x[i] = int((np.sum([np.power(y, i + 2) for y in eig_values])))\n",
    "        if walks_x[i] < 1:  # Handling of numerical nuisance\n",
    "            walks_x[i] = 0\n",
    "    return walks_x\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def run_svm(kernel_matrix, labels):\n",
    "    \"\"\"\n",
    "    Trains an SVM for the given kernel using 10-fold cross validation with 10 repititions.\n",
    "    The number of iterations of the SVM can be adjusted by adjusting the MAX_IT parameter. Naturally higher Values\n",
    "    lead to higher computation times and higher accuracies.\n",
    "    \n",
    "    We justify the cap by agruing that unreasonable computation\n",
    "    times outweigh the importance of perfect accuracy results. The accuracy will not proportionally increase with\n",
    "    computation time, but will almost remain the same, making unlimited number of iterations until convergence unfeasable.\n",
    "    Improving the runtime is certainly a work in progress. By scaling the data beforehand we tried to fix convergence issues,\n",
    "    especially with the enzymes dataset, but different scaling did not lead to success. \n",
    "    \n",
    "    :param kernel_matrix: name of the kernel to be used for training, possible options: \"graphlet\",\"wl\", \"closed_walk\"\n",
    "    :param labels: True labels for the graphs in the given dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    X = kernel_matrix\n",
    "    \n",
    "    #Scaling the kernel to values in range (0,1) to prevent long convergence times\n",
    "    scaler = MinMaxScaler() #Switching between MinMax and StandardScaler. We didnt see improved results between the two.\n",
    "    #scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    y = labels\n",
    "    clf = svm.SVC(kernel=\"precomputed\", max_iter = MAX_IT)\n",
    "    scores = model_selection.cross_val_score(clf, kernel_matrix, y,\n",
    "                                                       cv=RepeatedKFold(n_splits=10, n_repeats=10, random_state=345369))\n",
    "    print(\"The Accuracies per run were:\", scores, \"\\n\")\n",
    "    print(\"Thus the average accuracy over all runs was\", np.average(scores),\"\\n\")\n",
    "    print(\"With a standard deviation of \", np.std(scores))\n",
    "    print(\"and highest achieved Accuracy of \", np.max(scores),\".\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    By default this will use precomputed gram matrices for the closed walk kernel and train an SVM via 10fold crossvalidation\n",
    "    and 10 repeats. If the Flag COMPUTE_KERNEL_MATRICES is set, it will instead compute the Matrices from scratch, significantly inscreasing runtime\n",
    "    \"\"\"\n",
    "    \n",
    "    #Compute Kernel Matrixes from scratch if the Flag is set, by default disabled\n",
    "    if(COMPUTE_KERNEL_MATRICES):\n",
    "        matrix_set = compute_closed_walks_matrix(datasets,names)\n",
    "        #print(matrix_set[0]) refers to Dataset \"dd\"\n",
    "        #print(matrix_set[1]) refers to Dataset \"enzymes\"\n",
    "        #print(matrix_set[2]) refers to Dataset \"nci1\"\n",
    "\n",
    "        \n",
    "         #for explicit computation of specific datasets please use \n",
    "            #compute_closed_walks_matrix([datasets[0]],[\"dd\"]))\n",
    "            #compute_closed_walks_matrix([datasets[1]],[\"enzymes\"]))\n",
    "            #compute_closed_walks_matrix([datasets[3]],[\"nci1\"]))\n",
    "    \n",
    "    \n",
    "    names, datasets, labelsets = load_datasets()\n",
    "    \n",
    "    #Train and run the SVM on each dataset\n",
    "    for i, name in enumerate(names):\n",
    "        print(\"Currently training for dataset\", name)\n",
    "        kernel_matrix = load_kernel_matrix(name)\n",
    "        run_svm(kernel_matrix, labelsets[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
