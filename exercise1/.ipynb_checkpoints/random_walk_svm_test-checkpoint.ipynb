{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1117318316  685227904  437700776 ...   95620744   82035572  604403742]\n",
      " [ 685227904  420470176  268529400 ...   58682808   50349336  370644544]\n",
      " [ 437700776  268529400  171505912 ...   37475360   32152672  236757904]\n",
      " ...\n",
      " [  95620744   58682808   37475360 ...    8190376    7027400   51723056]\n",
      " [  82035572   50349336   32152672 ...    7027400    6029620   44374222]\n",
      " [ 604403742  370644544  236757904 ...   51723056   44374222  327013467]]\n",
      "[[4439124 2791356 1766730 ... 3899904 4052874 3128484]\n",
      " [2791356 1755244 1110774 ... 2452424 2548794 1967438]\n",
      " [1766730 1110774  704963 ... 1547756 1606115 1239777]\n",
      " ...\n",
      " [3899904 2452424 1547756 ... 3454736 3598064 2778988]\n",
      " [4052874 2548794 1606115 ... 3598064 3750617 2897010]\n",
      " [3128484 1967438 1239777 ... 2778988 2897010 2237809]]\n",
      "[[ 25480  32326  38276 ...  47124  54488  50414]\n",
      " [ 32326  41017  48575 ...  59787  69152  63962]\n",
      " [ 38276  48575  57538 ...  70794  81916  75739]\n",
      " ...\n",
      " [ 47124  59787  70794 ...  87154 100780  93239]\n",
      " [ 54488  69152  81916 ... 100780 116649 107845]\n",
      " [ 50414  63962  75739 ...  93239 107845  99774]]\n",
      "(600, 600)\n",
      "[[4439124 2791356 1766730 ... 3899904 4052874 3128484]\n",
      " [2791356 1755244 1110774 ... 2452424 2548794 1967438]\n",
      " [1766730 1110774  704963 ... 1547756 1606115 1239777]\n",
      " ...\n",
      " [3899904 2452424 1547756 ... 3454736 3598064 2778988]\n",
      " [4052874 2548794 1606115 ... 3598064 3750617 2897010]\n",
      " [3128484 1967438 1239777 ... 2778988 2897010 2237809]]\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from data_utils import get_adjacency_matrix\n",
    "from numpy import linalg as LA\n",
    "from progress.bar import Bar\n",
    "from data_utils import get_graph_label\n",
    "from dataset_parser import Parser\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "CLOSED_WALK_VECTOR_SIZE = 3 #maximal length of closed walks\n",
    "COMPUTE_KERNEL_MATRICES = False #Set true to compute all kernel matrixes from scratch, if false, the program will load previous results instead\n",
    "SVM_MAX_ITERATIONS = 10 #Number of Iterations for SVM classification\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"\n",
    "    Utility function returning the datasets as list of lists with respective names and true labels for each graph\n",
    "    \"\"\"\n",
    "    names = ['dd', 'enzymes', 'nci1']\n",
    "    #logging.info(\"[INFO] Loading datasets: {}, {}, {}.\"\n",
    "                # .format(names[0], names[1], names[2]))\n",
    "\n",
    "    dd = Parser('datasets/DD')\n",
    "    enzymes = Parser('datasets/ENZYMES')\n",
    "    nci1 = Parser('datasets/NCI1')\n",
    "\n",
    "    # convert datasets into lists graphs, labels\n",
    "    datasets = [dd.parse_all_graphs(),\n",
    "                enzymes.parse_all_graphs(),\n",
    "                nci1.parse_all_graphs()]\n",
    "\n",
    "    \n",
    "    label_sets = [[get_graph_label(graph) for graph in graphs] for graphs in datasets]\n",
    "\n",
    "    return names, datasets, label_sets\n",
    "\n",
    "def compute_closed_walks_matrix(datasets, names):\n",
    "    \"\"\"\n",
    "    Computes the closed walk kernel matrix for all datasets, will save all computed results in the process in the Folder \"data\"\n",
    "    \n",
    "    :param datasets: List of datasets, where each dataset is a list of NetworkX graphs\n",
    "    :param names: List of Strings, which are the names of the dataset at the respective index\n",
    "    \n",
    "    :return: Closed Walk Matrices for each dataset as a List of Matrices\n",
    "    \"\"\"\n",
    "    #Make directory accordingly\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), \"data/closed_walk\")):\n",
    "        os.makedirs(os.path.join(os.getcwd(), \"data\", \"closed_walk\"))\n",
    "\n",
    "    # Initialize Datastructures\n",
    "    closed_walk_sets = [] #holds the respective closed walk vector for each graph for all datasets\n",
    "    matrix_set = [] \n",
    "\n",
    "    #compute all closed walk vectors for each dataset respectively\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        closed_walks = np.zeros([len(dataset), CLOSED_WALK_VECTOR_SIZE],dtype=np.int32)\n",
    "        bar = Bar(\"Processing \" + names[i], max=len(dataset))\n",
    "        for j, graph in enumerate(dataset):\n",
    "            bar.next()\n",
    "            closed_walks[j] = closed_walks_vector(graph, CLOSED_WALK_VECTOR_SIZE)\n",
    "        bar.finish()\n",
    "        \n",
    "        #Compute the Kernel matrix once all graphs of a single dataset are processed\n",
    "        kernel_matrix = np.dot(closed_walks,closed_walks.T)\n",
    "        \n",
    "        #Save the kernel:matrix and the computed vectors seperatly\n",
    "        np.save(os.path.join(os.getcwd(),\n",
    "                            \"data\", \"closed_walk\", \"dataset_\" + names[i] + \".npy\"), closed_walks)\n",
    "        np.save(os.path.join(os.getcwd(),\n",
    "                            \"data\", \"closed_walk\", \"dataset_\" + names[i] + \"_matrix\"+\".npy\"), kernel_matrix)\n",
    "\n",
    "        closed_walk_sets.append(closed_walks)\n",
    "        matrix_set.append(kernel_matrix)\n",
    "        \n",
    "    #print(closed_walk_sets)\n",
    "    return matrix_set\n",
    "\n",
    "\n",
    "def load_closed_walks(names):\n",
    "    \"\"\"\n",
    "    Utility Function loading and returning saved npy files for closed walk vectors. Will return all vectors of the dataset\n",
    "    \n",
    "    :param name: List of Names of datasets (\"dd\", \"enzymes\",\"nci1\")\n",
    "    :return: List of the respective lists of vectors\n",
    "    \n",
    "    \"\"\"\n",
    "    closed_walk_sets = []\n",
    "    for name in names:\n",
    "        closed_walks = np.load(os.path.join(os.getcwd(),\n",
    "                                            \"data\", \"closed_walk\", \"dataset_\" + name + \".npy\"))\n",
    "        closed_walk_sets.append(closed_walks)\n",
    "    print(closed_walk_sets)    \n",
    "    return closed_walk_sets\n",
    "\n",
    "\n",
    "\n",
    "def load_kernel_matrix(name):\n",
    "    \"\"\"\n",
    "    Utility Function to return the specific closed walk kernel matrix for the given dataset\n",
    "    \n",
    "    :param name: Name of the dataset (\"dd\", \"enzymes\",\"nci1\")\n",
    "    :return: Kernel Matrix \n",
    "    \"\"\"\n",
    "    kernel_matrix = np.load(os.path.join(os.getcwd(),\n",
    "                                    \"data\", \"closed_walk\", \"dataset_\" + name+\"_matrix\" + \".npy\"))\n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def closed_walks_vector(x, max_i):\n",
    "    \"\"\"\n",
    "    Function calculating the vector of dimension max_i containing the number of closed walks of length 2 upto max_i\n",
    "    We make use of the spectral theorem for the calculation of the closed path number by using the eigenvalues\n",
    "    of the adjecency matrix\n",
    "    \n",
    "    :param x: A NetworkX Graph \n",
    "    \n",
    "    :return: Vector of dimension max_i, index i contains the number of closed walks of length i+2\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ##Initialization of used datastructures##\n",
    "    walks_x = np.zeros(max_i, dtype = np.int32)  # Vector holding the number of closed walks\n",
    "    eig_values, _ = LA.eig(get_adjacency_matrix(x))  # Vector holding the eigenvalues of the Adjecency Matrix\n",
    "\n",
    "    for i in range(max_i):\n",
    "        # Summation of the powered eigenvalues, we start with i+2\n",
    "        # since closed walks start with length 2. walks_x[0] will thus hold the walks of length 2, not 0.\n",
    "        walks_x[i] = int((np.sum([np.power(y, i + 2) for y in eig_values])))\n",
    "        if walks_x[i] < 1:  # Handling of numerical nuisance\n",
    "            walks_x[i] = 0\n",
    "    return walks_x\n",
    "\n",
    "\n",
    "def run_svm(kernel_matrix, labels):\n",
    "    \"\"\"\n",
    "    Trains an SVM for the given kernel using 10-fold cross validation with 10 repititions.\n",
    "    \n",
    "    :param kernel_matrix: name of the kernel to be used for training, possible options: \"graphlet\",\"wl\", \"closed_walk\"\n",
    "    :param labels: True labels for the graphs in the given dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    X = kernel_matrix\n",
    "    y = label_sets[1]\n",
    "    rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=345369)\n",
    "    clf = svm.SVC(kernel=\"precomputed\", max_iter= 5)\n",
    "    scores = model_selection.cross_val_score(clf, kernel_matrix, y,\n",
    "                                                       cv=RepeatedKFold(n_splits=10, n_repeats=10, random_state=345369))\n",
    "    print(\"The Accuracies per run were:\", scores, \"\\n\")\n",
    "    print(\"Thus the average accuracy over all runs was\", np.average(scores),\"\\n\")\n",
    "    print(\"With a standard deviation of \", np.std(scores), \".\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    By default this will use precomputed gram matrices for the closed walk kernel and train an SVM via 10fold crossvalidation\n",
    "    and 10 repeats. If the Flag COMPUTE_KERNEL_MATRICES is set, it will instead compute the Matrices from scratch, significantly inscreasing runtime\n",
    "    \"\"\"\n",
    "    \n",
    "    #Compute Kernel Matrixes from scratch if the Flag is set, by default disabled\n",
    "    if(COMPUTE_KERNEL_MATRICES):\n",
    "        matrix_set = compute_closed_walks_matrix(datasets,names)\n",
    "        #print(matrix_set[0]) refers to Dataset \"dd\"\n",
    "        #print(matrix_set[1]) refers to Dataset \"enzymes\"\n",
    "        #print(matrix_set[2]) refers to Dataset \"nci1\"\n",
    "\n",
    "        \n",
    "         #for explicit computation of specific datasets please use \n",
    "            #compute_closed_walks_matrix([datasets[0]],[\"dd\"]))\n",
    "            #compute_closed_walks_matrix([datasets[1]],[\"enzymes\"]))\n",
    "            #compute_closed_walks_matrix([datasets[3]],[\"nci1\"]))\n",
    "    \n",
    "    \n",
    "    names, datasets, labelsets = load_datasets()\n",
    "    \n",
    "    #Train and run the SVM on each dataset\n",
    "    for i, name in enumerate(names):\n",
    "        kernel_matrix = load_kernel_matrix(name)\n",
    "        run_svm(kernel_matrix, labelsets[i])\n",
    "\n",
    "    #kernel_matrix = load_kernel_matrix(\"enzymes\")\n",
    "    #run_svm(kernel_matrix, labelsets)\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
