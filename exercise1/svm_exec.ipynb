{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current kernel is: WL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5329f025f840578c3066357bce9eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting dd', max=1178.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac87e97e51fd419283407460bc38183b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting enzymes', max=600.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0f7852587a403a921cdceb9389d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting nci1', max=4110.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Gram Matrix\n",
      "Computing of gram matrix complete, starting SVM training of dataset dd\n",
      "The Accuracies per run were: [0.52542373 0.59322034 0.6779661  0.61864407 0.42372881 0.70338983\n",
      " 0.66949153 0.40677966 0.55555556 0.72649573 0.61864407 0.60169492\n",
      " 0.61016949 0.58474576 0.6779661  0.63559322 0.28813559 0.66101695\n",
      " 0.64102564 0.51282051 0.66949153 0.58474576 0.42372881 0.66101695\n",
      " 0.63559322 0.59322034 0.55084746 0.66949153 0.47008547 0.41025641\n",
      " 0.76271186 0.33050847 0.56779661 0.34745763 0.66101695 0.34745763\n",
      " 0.41525424 0.62711864 0.57264957 0.60683761 0.5        0.40677966\n",
      " 0.71186441 0.37288136 0.62711864 0.52542373 0.62711864 0.57627119\n",
      " 0.67521368 0.68376068 0.37288136 0.54237288 0.48305085 0.60169492\n",
      " 0.60169492 0.56779661 0.65254237 0.66101695 0.65811966 0.55555556\n",
      " 0.38135593 0.53389831 0.63559322 0.33898305 0.77966102 0.51694915\n",
      " 0.58474576 0.61864407 0.34188034 0.54700855 0.59322034 0.61016949\n",
      " 0.33050847 0.59322034 0.57627119 0.33898305 0.48305085 0.68644068\n",
      " 0.53846154 0.7008547  0.66101695 0.41525424 0.62711864 0.66949153\n",
      " 0.66101695 0.66101695 0.44915254 0.29661017 0.47008547 0.64957265\n",
      " 0.27966102 0.37288136 0.55932203 0.37288136 0.39830508 0.49152542\n",
      " 0.66949153 0.30508475 0.58119658 0.52136752] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.5488490511371868 \n",
      "\n",
      "With a standard deviation of  0.12258594064356244\n",
      "and highest achieved Accuracy of  0.7796610169491526 .\n",
      "Computing Gram Matrix\n",
      "Computing of gram matrix complete, starting SVM training of dataset enzymes\n",
      "The Accuracies per run were: [0.2        0.18333333 0.21666667 0.11666667 0.2        0.2\n",
      " 0.1        0.2        0.25       0.25       0.25       0.21666667\n",
      " 0.16666667 0.16666667 0.13333333 0.13333333 0.21666667 0.16666667\n",
      " 0.11666667 0.16666667 0.25       0.15       0.18333333 0.15\n",
      " 0.21666667 0.2        0.18333333 0.18333333 0.23333333 0.13333333\n",
      " 0.2        0.2        0.25       0.2        0.16666667 0.21666667\n",
      " 0.21666667 0.25       0.13333333 0.23333333 0.18333333 0.18333333\n",
      " 0.1        0.25       0.11666667 0.21666667 0.15       0.18333333\n",
      " 0.31666667 0.16666667 0.21666667 0.26666667 0.18333333 0.18333333\n",
      " 0.18333333 0.15       0.13333333 0.2        0.3        0.18333333\n",
      " 0.18333333 0.2        0.2        0.28333333 0.13333333 0.11666667\n",
      " 0.21666667 0.23333333 0.23333333 0.21666667 0.16666667 0.13333333\n",
      " 0.16666667 0.25       0.18333333 0.2        0.16666667 0.25\n",
      " 0.15       0.15       0.2        0.16666667 0.2        0.23333333\n",
      " 0.13333333 0.18333333 0.16666667 0.13333333 0.23333333 0.2\n",
      " 0.15       0.23333333 0.28333333 0.18333333 0.21666667 0.18333333\n",
      " 0.26666667 0.25       0.08333333 0.18333333] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.1918333333333333 \n",
      "\n",
      "With a standard deviation of  0.045976745329689345\n",
      "and highest achieved Accuracy of  0.31666666666666665 .\n",
      "Computing Gram Matrix\n",
      "Computing of gram matrix complete, starting SVM training of dataset nci1\n",
      "The Accuracies per run were: [0.46715328 0.46958637 0.45985401 0.51824818 0.41849148 0.40632603\n",
      " 0.44282238 0.42579075 0.58394161 0.46472019 0.45255474 0.54744526\n",
      " 0.48905109 0.45985401 0.46715328 0.41605839 0.56447689 0.4622871\n",
      " 0.51581509 0.50608273 0.43309002 0.45498783 0.46472019 0.44768856\n",
      " 0.47201946 0.49635036 0.49148418 0.47688564 0.39902676 0.51094891\n",
      " 0.43552311 0.44525547 0.52311436 0.4379562  0.47931873 0.50121655\n",
      " 0.49635036 0.61557178 0.58150852 0.48905109 0.38686131 0.64233577\n",
      " 0.44038929 0.486618   0.47931873 0.45985401 0.50121655 0.486618\n",
      " 0.43065693 0.56447689 0.39902676 0.45985401 0.52798054 0.47201946\n",
      " 0.45985401 0.44038929 0.49878345 0.49148418 0.58150852 0.40389294\n",
      " 0.45255474 0.45742092 0.54501217 0.48175182 0.62287105 0.50364964\n",
      " 0.57664234 0.51094891 0.44038929 0.55961071 0.45255474 0.45742092\n",
      " 0.46715328 0.45742092 0.61800487 0.44525547 0.45742092 0.52554745\n",
      " 0.44282238 0.49878345 0.48418491 0.59367397 0.4379562  0.44038929\n",
      " 0.46472019 0.45255474 0.56690998 0.58150852 0.58880779 0.45985401\n",
      " 0.47931873 0.42822384 0.44038929 0.55717762 0.48905109 0.45255474\n",
      " 0.45498783 0.47688564 0.47201946 0.45985401] \n",
      "\n",
      "Thus the average accuracy over all runs was 0.48557177615571784 \n",
      "\n",
      "With a standard deviation of  0.05451018239599815\n",
      "and highest achieved Accuracy of  0.6423357664233577 .\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 4\n",
    "Code for training the SVM on the datasets DD, ENZYMES and NCI1.\n",
    "For choosing a kernel, set the KERNEL_TYPE flag in the config.py module.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import config\n",
    "from graphlet import compute_graphlets, load_graphlets\n",
    "from closed_walk_svm_test import compute_closed_walks_matrix, load_closed_walks, load_kernel_matrix\n",
    "from wl_kernel import get_wl_hist, compute_wl\n",
    "from data_utils import get_graph_label\n",
    "from dataset_parser import Parser\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import svm, model_selection\n",
    "from sklearn.model_selection import cross_validate, RepeatedKFold\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "MAX_IT = 30000 #number of maximal iterations for SVM, defaults to infinity (until convergence), adjust for better runtime\n",
    "def load_datasets(names):\n",
    "    \"\"\"\n",
    "    Loads the graph datasets DD, ENZYMES and NCI1 and its labels.\n",
    "    :params:    list of dataset names to load\n",
    "\n",
    "    :return:    list of dataset names, list of loaded graphs for all datasets,\n",
    "                labels for loaded graphs for all datasets\n",
    "    \"\"\"\n",
    "\n",
    "    # load datasets\n",
    "    datasets = []\n",
    "    if \"dd\" in names:\n",
    "        datasets.append(Parser('datasets/DD'))\n",
    "    if \"enzymes\" in names:\n",
    "        datasets.append(Parser('datasets/ENZYMES'))\n",
    "    if \"nci1\" in names:\n",
    "        datasets.append(Parser('datasets/NCI1'))\n",
    "\n",
    "    # convert datasets into lists graphs, labels\n",
    "    datasets = [dataset.parse_all_graphs() for dataset in datasets]\n",
    "    label_sets = [[get_graph_label(graph) for graph in graphs] for graphs in datasets]\n",
    "\n",
    "    return names, datasets, label_sets\n",
    "\n",
    "\n",
    "def compute_gram_matrix(x):\n",
    "    \"\"\"\n",
    "    Kernel function calculating the inner product.\n",
    "\n",
    "    :param x: list of feature vectors\n",
    "    :return: gram matrix\n",
    "    \"\"\"\n",
    "    print(\"Computing Gram Matrix\")\n",
    "    return linear_kernel(x, x, dense_output=True)\n",
    "\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def run_svm(kernel_matrix, labels, max_it):\n",
    "    \"\"\"\n",
    "    Trains an SVM for the given kernel using 10-fold cross validation with 10 repetitions.\n",
    "    The number of iterations of the SVM can be adjusted by adjusting the MAX_IT parameter. Naturally higher Values\n",
    "    lead to higher computation times and higher accuracies.\n",
    "\n",
    "    We justify the cap by arguing that unreasonable computation times outweigh the importance of perfect accuracy\n",
    "    results. The accuracy will not proportionally increase with computation time, but will almost remain the same,\n",
    "    making unlimited number of iterations until convergence unfeasible. Improving the runtime is certainly a work in\n",
    "    progress. By scaling the data beforehand we tried to fix convergence issues, especially with the enzymes dataset,\n",
    "    but different scaling did not lead to success.\n",
    "\n",
    "    :param kernel_matrix: precomputed gram matrix of the kernel to be used\n",
    "    :param label_sets: list of labels for the dataset\n",
    "    :param max_it: number of maximal iterations\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    X = kernel_matrix\n",
    "    \n",
    "    #Scaling the kernel to values in range (0,1) to prevent long convergence times\n",
    "    scaler = MinMaxScaler() #Switching between MinMax and StandardScaler. We didnt see improved results between the two.\n",
    "    #scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    y = labels\n",
    "    clf = svm.SVC(kernel=\"precomputed\", max_iter = max_it)\n",
    "    scores = model_selection.cross_val_score(clf, kernel_matrix, y,\n",
    "                                                       cv=RepeatedKFold(n_splits=10, n_repeats=10, random_state=345369))\n",
    "    print(\"The Accuracies per run were:\", scores, \"\\n\")\n",
    "    print(\"Thus the average accuracy over all runs was\", np.average(scores),\"\\n\")\n",
    "    print(\"With a standard deviation of \", np.std(scores))\n",
    "    print(\"and highest achieved Accuracy of \", np.max(scores),\".\")\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Optionally enable the loading of the respective kernel vectors instead of recomputing them on the fly to decrease\n",
    "    computation time\n",
    "    \n",
    "    Optionally manually adjust the MAX_IT parameter. \n",
    "\n",
    "    \"\"\"\n",
    "    names, datasets, labelsets = load_datasets(['dd', 'enzymes', 'nci1'])\n",
    "    print(\"The current kernel is:\",config.KERNEL_TYPE)\n",
    "    if config.KERNEL_TYPE == \"Graphlet\":\n",
    "        # remove graphs with cardinality smaller 5, as they cannot be used for our graphlet kernel\n",
    "        datasets = [[graph for graph in graphs if len(list(graph)) >= 5] for graphs in datasets]\n",
    "        \n",
    "        # vectors = compute_graphlets(datasets, names)\n",
    "        vectors = load_graphlets(names)\n",
    "        max_it = MAX_IT\n",
    "\n",
    "        \n",
    "        for i, name in enumerate(names):\n",
    "            kernel_matrix = compute_gram_matrix(vectors[i])\n",
    "            print(\"Computing of gram matrix complete, starting SVM training of dataset\", name)\n",
    "            run_svm(kernel_matrix, labelsets[i],max_it)\n",
    "        \n",
    "    elif config.KERNEL_TYPE == \"WL\":\n",
    "        vectors = compute_wl(datasets, names)\n",
    "        # vectors = load_wl(names)\n",
    "        max_it = MAX_IT\n",
    "\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            \n",
    "            kernel_matrix = compute_gram_matrix(vectors[i])\n",
    "            print(\"Computing of gram matrix complete, starting SVM training of dataset\", name)\n",
    "            run_svm(kernel_matrix, labelsets[i],max_it)\n",
    "        \n",
    "    elif config.KERNEL_TYPE == \"Closed_walk\":\n",
    "        for i, name in enumerate(names):\n",
    "            max_it = 10000\n",
    "            kernel_matrix = load_kernel_matrix(name)\n",
    "            print(\"Computing of gram matrix complete, starting SVM training of dataset\", name)\n",
    "            run_svm(kernel_matrix, labelsets[i],max_it)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid kernel type\", sys.exc_info()[0])\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
